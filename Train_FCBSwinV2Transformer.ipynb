{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgbnI1kmCdOT"
   },
   "source": [
    "# Import Python Modules, Dataset Creator, Scoring Metrics and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01FC0Vr3Ccbp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "# Custom modules\n",
    "import LOADER\n",
    "import SIA_METRICS\n",
    "import FCBSWINV2_TRANSFORMER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define 'Results Folder' name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8pgJMoulciO"
   },
   "outputs": [],
   "source": [
    "save_string = \"RESULTS_FOLDER_NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCqSCDZbUhwz"
   },
   "source": [
    "# Create ID, Image and Masks Data from folder of images and CSV file IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5094,
     "status": "ok",
     "timestamp": 1692884638807,
     "user": {
      "displayName": "Kerr Fitzgerald",
      "userId": "02804875987175492878"
     },
     "user_tz": -60
    },
    "id": "Pr_HTRGsl2wf",
    "outputId": "6020c4cb-64db-4a03-f913-a4addd6ee095"
   },
   "outputs": [],
   "source": [
    "train_IDs, train_X, train_Y = LOADER.load_data_to_model(384, \"PATH TO 384x384 RESIZED IMAGES & MASKS FOLDER\", \"PATH TO TRAIN DATA SPLIT csv FILE\")\n",
    "valid_IDs, valid_X, valid_Y = LOADER.load_data_to_model(384, \"PATH TO 384x384 RESIZED IMAGES & MASKS FOLDER\", \"PATH TO VALID DATA SPLIT csv FILE\")\n",
    "test_IDs,  test_X,  test_Y =  LOADER.load_data_to_model(384, \"PATH TO 384x384 RESIZED IMAGES & MASKS FOLDER\", \"PATH TO TEST  DATA SPLIT csv FILE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc6qidTiEnKk"
   },
   "source": [
    "# Define Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwVeqiMjmC3g"
   },
   "outputs": [],
   "source": [
    "geometric = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.Affine(scale=(0.5,1.5), translate_percent=(-0.125,0.125), rotate=(-180,180), shear=(-22.5,22), always_apply=True)\n",
    "])\n",
    "\n",
    "color = A.Compose([\n",
    "    A.ColorJitter(brightness=(0.6,1.6), contrast=0.2, saturation=0.1, hue=0.01, always_apply=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plvbUW149D8X"
   },
   "source": [
    "# Create Train, Validation and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICDrTLsxmKKi"
   },
   "outputs": [],
   "source": [
    "train_dataset = LOADER.Polyp_Dataset(train_IDs, train_X, train_Y, geo_transform=geometric, color_transform=color)\n",
    "valid_dataset = LOADER.Polyp_Dataset(valid_IDs, valid_X, valid_Y, geo_transform=None, color_transform=None)\n",
    "test_dataset =  LOADER.Polyp_Dataset(test_IDs,  test_X,  test_Y, geo_transform=None, color_transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7S1FapM9KYI"
   },
   "source": [
    "# Create Train, Validation and Test Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 2\n",
    "valid_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=6)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=valid_batch_size, shuffle=False, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfI8m-jk9Rna"
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2440,
     "status": "ok",
     "timestamp": 1692884641238,
     "user": {
      "displayName": "Kerr Fitzgerald",
      "userId": "02804875987175492878"
     },
     "user_tz": -60
    },
    "id": "ZVMobQWZmWfp",
    "outputId": "2e00bf3d-c91b-464d-bc13-e55b05e38608"
   },
   "outputs": [],
   "source": [
    "model = FCBSWINV2_TRANSFORMER.FCBSwinV2_Transformer(size=384, checkpoint_path=\"PATH TO PRE-TRAINED SWINV2 MODEL WEIGHTS)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ejyr1BF19VMe"
   },
   "source": [
    "# Define PyTorch Optimizer, Scheduler and Loss Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clyj3WlHmWiw"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.6, patience=10)\n",
    "# Custom scoring functions for image-wise averaging\n",
    "criterion = SIA_METRICS.DiceBCELoss()\n",
    "dice = SIA_METRICS.DiceLoss()\n",
    "IoU  = SIA_METRICS.IoULoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pi6cnYwEv51O"
   },
   "source": [
    "# Train the model and evaluate on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322204,
     "status": "ok",
     "timestamp": 1692890856714,
     "user": {
      "displayName": "Kerr Fitzgerald",
      "userId": "02804875987175492878"
     },
     "user_tz": -60
    },
    "id": "R2c3_O84kDgt",
    "outputId": "a163e961-dc41-4b0c-b26d-d1c824b427e6"
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "start_epoch = 0\n",
    "\n",
    "max_trn_batch = 1000000\n",
    "max_val_batch = 1000000\n",
    "\n",
    "# Dataset Sizes\n",
    "train_size = len(train_dataset)\n",
    "valid_size = len(valid_dataset)\n",
    "\n",
    "# Initialise multiclass scores and losses lists\n",
    "train_ce_losses_lst = []\n",
    "valid_ce_losses_lst = []\n",
    "\n",
    "train_dice_losses_lst = []\n",
    "valid_dice_losses_lst = []\n",
    "\n",
    "train_dice_scores_lst = []\n",
    "valid_dice_scores_lst = []\n",
    "\n",
    "train_thresh_dice_losses_lst = []\n",
    "valid_thresh_dice_losses_lst = []\n",
    "\n",
    "train_thresh_dice_scores_lst = []\n",
    "valid_thresh_dice_scores_lst = []\n",
    "\n",
    "train_iou_losses_lst = []\n",
    "valid_iou_losses_lst = []\n",
    "\n",
    "train_iou_scores_lst = []\n",
    "valid_iou_scores_lst = []\n",
    "\n",
    "train_thresh_iou_losses_lst = []\n",
    "valid_thresh_iou_losses_lst = []\n",
    "\n",
    "train_thresh_iou_scores_lst = []\n",
    "valid_thresh_iou_scores_lst = []\n",
    "\n",
    "train_precision_score_lst = []\n",
    "valid_precision_score_lst = []\n",
    "\n",
    "train_recall_score_lst = []\n",
    "valid_recall_score_lst = []\n",
    "\n",
    "# Track minimum validation loss and maximum validation Dice and IOU scores\n",
    "min_val_loss = 100\n",
    "max_val_dice = 0\n",
    "max_val_tice = 0\n",
    "\n",
    "# Initialise learning rate list\n",
    "lrs = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    # Initialise epoch start time\n",
    "    tic = time.time()\n",
    "\n",
    "    # Track images being processed\n",
    "    train_img_pro = 0\n",
    "    valid_img_pro = 0\n",
    "\n",
    "    # Initialise scores and losses to 0\n",
    "    total_train_ce_loss = 0\n",
    "    total_valid_ce_loss = 0\n",
    "\n",
    "    total_train_dice_loss = 0\n",
    "    total_valid_dice_loss = 0\n",
    "\n",
    "    total_train_dice_score= 0\n",
    "    total_valid_dice_score = 0\n",
    "\n",
    "    total_train_thresh_dice_loss = 0\n",
    "    total_valid_thresh_dice_loss = 0\n",
    "\n",
    "    total_train_thresh_dice_score= 0\n",
    "    total_valid_thresh_dice_score = 0\n",
    "\n",
    "    total_train_iou_loss = 0\n",
    "    total_valid_iou_loss = 0\n",
    "\n",
    "    total_train_iou_score = 0\n",
    "    total_valid_iou_score = 0\n",
    "\n",
    "    total_train_thresh_iou_loss = 0\n",
    "    total_valid_thresh_iou_loss = 0\n",
    "\n",
    "    total_train_thresh_iou_score = 0\n",
    "    total_valid_thresh_iou_score = 0\n",
    "\n",
    "    total_train_precision_score = 0\n",
    "    total_valid_precision_score = 0\n",
    "\n",
    "    total_train_recall_score = 0\n",
    "    total_valid_recall_score = 0\n",
    "\n",
    "    # Append current learning rate to list\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    print(\"LR for epoch \", i,\" = \", optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    # Run the training batches\n",
    "    for b, (name, img_train, msk_train) in enumerate(train_loader):\n",
    "        img_train, msk_train = img_train.to(device), msk_train.float().to(device)\n",
    "\n",
    "        # Load image tensor from train_loader\n",
    "        #print(\"img_train: \", img_train.size())\n",
    "\n",
    "        # Load ground truth mask tensor from train_loader\n",
    "        #print(\"msk_train: \", msk_train.size())\n",
    "\n",
    "        # Apply the model\n",
    "        pred = model(img_train)\n",
    "        #print(\"pred:      \", pred.size())\n",
    "        # Track Number of Images Processed\n",
    "        train_img_pro += pred.size()[0]\n",
    "        #print(\"Batch: \", b, \"img_pro\", train_img_pro)\n",
    "\n",
    "        # Apply sigmoid activation (needed fo dice and IoU loss calculations)\n",
    "        output = torch.sigmoid(pred)\n",
    "\n",
    "        # Calculate loss\n",
    "        # Scoring loss metrics for binary case\n",
    "        train_dice_loss = dice(output, msk_train)\n",
    "        train_dice_score = 1 - train_dice_loss\n",
    "\n",
    "        loss = criterion(output, msk_train)\n",
    "\n",
    "        train_iou_loss  = IoU(output, msk_train)\n",
    "        train_iou_score = 1 - train_iou_loss\n",
    "\n",
    "        train_thresh_dice_loss = SIA_METRICS.Threshold_DiceLoss(output, msk_train, thresh=0.5, smooth=1e-6)\n",
    "        train_thresh_dice_score = 1 - train_thresh_dice_loss\n",
    "\n",
    "        train_thresh_iou_loss = SIA_METRICS.Threshold_IoULoss(output, msk_train, thresh=0.5, smooth=1e-6)\n",
    "        train_thresh_iou_score = 1 - train_thresh_iou_loss\n",
    "\n",
    "        train_precision_score = SIA_METRICS.custom_precision_score(output, msk_train, thresh=0.5, smooth=1e-6)\n",
    "        train_recall_score =  SIA_METRICS.custom_recall_score(output, msk_train, thresh=0.5, smooth=1e-6)\n",
    "\n",
    "        # Limit the number of batches\n",
    "        if b == max_trn_batch:\n",
    "            break\n",
    "        b+=1\n",
    "\n",
    "        # Track the total multi-class losses to get epoch averages\n",
    "        total_train_ce_loss += loss.item()\n",
    "\n",
    "        total_train_dice_loss += train_dice_loss.item()\n",
    "        total_train_dice_score += train_dice_score.item()\n",
    "\n",
    "        total_train_iou_loss += train_iou_loss.item()\n",
    "        total_train_iou_score += train_iou_score.item()\n",
    "\n",
    "        total_train_thresh_dice_loss +=  train_thresh_dice_loss.item()\n",
    "        total_train_thresh_dice_score += train_thresh_dice_score.item()\n",
    "\n",
    "        total_train_thresh_iou_loss +=  train_thresh_iou_loss.item()\n",
    "        total_train_thresh_iou_score += train_thresh_iou_score.item()\n",
    "\n",
    "        total_train_precision_score += train_precision_score.item()\n",
    "        total_train_recall_score += train_recall_score.item()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print interim results\n",
    "        if b%(100*train_batch_size) == 0:\n",
    "            print('*****************************************************************************************************************')\n",
    "            print(f'EPOCH: {(i+start_epoch):2} BATCH: {b:4} [{train_img_pro:6}/{train_size}] COMB LOSS: {total_train_ce_loss/math.ceil((train_img_pro/train_batch_size)):7.5f} DICE LOSS: {total_train_dice_loss/math.ceil((train_img_pro/train_batch_size)):7.5f} IOU LOSS: {total_train_iou_loss/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "            print(f'                                                      TICE LOSS: {total_train_thresh_dice_loss/math.ceil((train_img_pro/train_batch_size)):7.5f} TOU LOSS: {total_train_thresh_iou_loss/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "            print(f'                                                      DICE SCRE: {total_train_dice_score/math.ceil((train_img_pro/train_batch_size)):7.5f} IOU SCRE: {total_train_iou_score/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "            print(f'                                                      TICE SCRE: {total_train_thresh_dice_score/math.ceil((train_img_pro/train_batch_size)):7.5f} TOU SCRE: {total_train_thresh_iou_score/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "            print(f'                                                      PREC SCRE: {total_train_precision_score/math.ceil((train_img_pro/train_batch_size)):7.5f} REC SCRE: {total_train_recall_score/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "            print(f'                                                      TIME:  {((time.time()-tic)/60):5.2f} ')\n",
    "\n",
    "    # Append average training loss of epoch to list\n",
    "    train_ce_losses_lst.append(total_train_ce_loss/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_dice_losses_lst.append(total_train_dice_loss/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_thresh_dice_losses_lst.append(total_train_thresh_dice_loss/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_thresh_iou_losses_lst.append(total_train_thresh_iou_loss/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_iou_losses_lst.append(total_train_iou_loss/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_precision_score_lst.append(total_train_precision_score/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_recall_score_lst.append(total_train_recall_score/math.ceil((train_img_pro/train_batch_size)))\n",
    "\n",
    "    train_dice_scores_lst.append(total_train_dice_score/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_thresh_dice_scores_lst.append(total_train_thresh_dice_score/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_iou_scores_lst.append(total_train_iou_score/math.ceil((train_img_pro/train_batch_size)))\n",
    "    train_thresh_iou_scores_lst.append(total_train_iou_score/math.ceil((train_img_pro/train_batch_size)))\n",
    "\n",
    "    # Print epoch training results\n",
    "    print('#################################################################################################################')\n",
    "    print(f'EPOCH: {(i+start_epoch):2} TRN COMB LOSS: {total_train_ce_loss/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "    print(f'              DICE LOSS: {total_train_dice_loss/math.ceil((train_img_pro/train_batch_size)):7.5f} IOU LOSS: {total_train_iou_loss/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "    print(f'              TICE LOSS: {total_train_thresh_dice_loss/math.ceil((train_img_pro/train_batch_size)):7.5f} TOU LOSS: {total_train_thresh_iou_loss/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "    print(f'              DICE SCRE: {total_train_dice_score/math.ceil((train_img_pro/train_batch_size)):7.5f} IOU SCRE: {total_train_iou_score/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "    print(f'              TICE SCRE: {total_train_thresh_dice_score/math.ceil((train_img_pro/train_batch_size)):7.5f} TOU SCRE: {total_train_thresh_iou_score/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "    print(f'              PREC SCRE: {total_train_precision_score/math.ceil((train_img_pro/train_batch_size)):7.5f} REC SCRE: {total_train_recall_score/math.ceil((train_img_pro/train_batch_size)):7.5f}')\n",
    "    print(f'              TIME:  {((time.time()-tic)/60):5.2f} ')\n",
    "    print('#################################################################################################################')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for b, (name, img_valid, msk_valid) in enumerate(valid_loader):\n",
    "            img_valid, msk_valid = img_valid.to(device), msk_valid.float().to(device)\n",
    "\n",
    "            # Load image tensor from valid_loader\n",
    "            #print(\"img_valid: \", img_valid.size())\n",
    "\n",
    "            # Apply the model\n",
    "            pred = model(img_valid)\n",
    "            # Track Number of Images Processed\n",
    "            valid_img_pro += pred.size()[0]\n",
    "            #print(\"Batch: \", b, \"img_pro\", valid_img_pro)\n",
    "\n",
    "            # Apply sigmoid activation (needed fo dice and IoU loss calculations)\n",
    "            output = torch.sigmoid(pred)\n",
    "\n",
    "            # Calculate loss\n",
    "            #loss = criterion(pred, msk_valid)\n",
    "\n",
    "            # Scoring loss metrics for binary case\n",
    "            valid_dice_loss = dice(output, msk_valid)\n",
    "            valid_dice_score = 1 - valid_dice_loss\n",
    "\n",
    "            loss = criterion(output, msk_valid)\n",
    "\n",
    "            valid_iou_loss  = IoU(output, msk_valid)\n",
    "            valid_iou_score = 1 - valid_iou_loss\n",
    "\n",
    "            # Calculate thresholded values\n",
    "            valid_thresh_dice_loss = SIA_METRICS.Threshold_DiceLoss(output, msk_valid, thresh=0.5, smooth=1)\n",
    "            valid_thresh_dice_score = 1 - valid_thresh_dice_loss\n",
    "\n",
    "            valid_thresh_iou_loss = SIA_METRICS.Threshold_IoULoss(output, msk_valid, thresh=0.5, smooth=1)\n",
    "            valid_thresh_iou_score = 1 - valid_thresh_iou_loss\n",
    "\n",
    "            valid_precision_score = SIA_METRICS.custom_precision_score(output, msk_valid, thresh=0.5, smooth=1)\n",
    "            valid_recall_score =  SIA_METRICS.custom_recall_score(output, msk_valid, thresh=0.5, smooth=1)\n",
    "\n",
    "            # Limit the number of batches\n",
    "            if b == max_trn_batch:\n",
    "                break\n",
    "            b+=1\n",
    "\n",
    "            # Track the total multi-class losses to get epoch averages\n",
    "            total_valid_ce_loss += loss.item()\n",
    "\n",
    "            total_valid_dice_loss += valid_dice_loss.item()\n",
    "            total_valid_dice_score += valid_dice_score.item()\n",
    "\n",
    "            total_valid_iou_loss += valid_iou_loss.item()\n",
    "            total_valid_iou_score += valid_iou_score.item()\n",
    "\n",
    "            total_valid_thresh_dice_loss +=  valid_thresh_dice_loss.item()\n",
    "            total_valid_thresh_dice_score += valid_thresh_dice_score.item()\n",
    "\n",
    "            total_valid_thresh_iou_loss +=  valid_thresh_iou_loss.item()\n",
    "            total_valid_thresh_iou_score += valid_thresh_iou_score.item()\n",
    "\n",
    "            total_valid_precision_score += valid_precision_score.item()\n",
    "            total_valid_recall_score += valid_recall_score.item()\n",
    "\n",
    "            # Print interim results\n",
    "            if b%(100*valid_batch_size) == 0:\n",
    "                print('*****************************************************************************************************************')\n",
    "                print(f'EPOCH: {(i+start_epoch):2} BATCH: {b:4} [{valid_img_pro:6}/{valid_size}] COMB LOSS: {total_valid_ce_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f} DICE LOSS: {total_valid_dice_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f} IOU LOSS: {total_valid_iou_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "                print(f'                                                      TICE LOSS: {total_valid_thresh_dice_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f} TOU LOSS: {total_valid_thresh_iou_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "                print(f'                                                      DICE SCRE: {total_valid_dice_score/math.ceil(valid_img_pro/valid_batch_size):7.5f} IOU SCRE: {total_valid_iou_score/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "                print(f'                                                      TICE SCRE: {total_valid_thresh_dice_score/math.ceil(valid_img_pro/valid_batch_size):7.5f} TOU SCRE: {total_valid_thresh_iou_score/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "                print(f'                                                      PREC SCRE: {total_valid_precision_score/math.ceil(valid_img_pro/valid_batch_size):7.5f} REC SCRE: {total_valid_recall_score/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "                print(f'                                                      TIME:  {((time.time()-tic)/60):5.2f} ')\n",
    "\n",
    "        # Append average validing loss of epoch to list\n",
    "        valid_ce_losses_lst.append(total_valid_ce_loss/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_dice_losses_lst.append(total_valid_dice_loss/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_thresh_dice_losses_lst.append(total_valid_thresh_dice_loss/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_thresh_iou_losses_lst.append(total_valid_thresh_iou_loss/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_iou_losses_lst.append(total_valid_iou_loss/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_precision_score_lst.append(total_valid_precision_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_recall_score_lst.append(total_valid_recall_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "\n",
    "        valid_dice_scores_lst.append(total_valid_dice_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_thresh_dice_scores_lst.append(total_valid_thresh_dice_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_iou_scores_lst.append(total_valid_iou_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "        valid_thresh_iou_scores_lst.append(total_valid_thresh_iou_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "\n",
    "        # Print epoch validation results\n",
    "        print('#################################################################################################################')\n",
    "        print(f'EPOCH: {(i+start_epoch):2} VAL COMB LOSS: {total_valid_ce_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "        print(f'              DICE LOSS: {total_valid_dice_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f} IOU LOSS: {total_valid_iou_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "        print(f'              TICE LOSS: {total_valid_thresh_dice_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f} TOU LOSS: {total_valid_thresh_iou_loss/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "        print(f'              DICE SCRE: {total_valid_dice_score/math.ceil(valid_img_pro/valid_batch_size):7.5f} IOU SCRE: {total_valid_iou_score/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "        print(f'              TICE SCRE: {total_valid_thresh_dice_score/math.ceil(valid_img_pro/valid_batch_size):7.5f} TOU SCRE: {total_valid_thresh_iou_score/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "        print(f'              PREC SCRE: {total_valid_precision_score/math.ceil(valid_img_pro/valid_batch_size):7.5f} REC SCRE: {total_valid_recall_score/math.ceil(valid_img_pro/valid_batch_size):7.5f}')\n",
    "        print(f'              TIME:  {((time.time()-tic)/60):5.2f} ')\n",
    "        print('#################################################################################################################')\n",
    "        scheduler.step(min_val_loss)\n",
    "        if i>5:\n",
    "            if (total_valid_ce_loss/math.ceil(valid_img_pro/valid_batch_size)) <= min_val_loss:\n",
    "                print(\"SAVING MIN VAL COMB LOSS MODEL\")\n",
    "                min_val_loss = (total_valid_ce_loss/math.ceil(valid_img_pro/valid_batch_size))\n",
    "                torch.save(model.state_dict(), save_string + \"_min_val_comb_loss.pt\")\n",
    "            if (total_valid_dice_score/math.ceil(valid_img_pro/valid_batch_size)) >= max_val_dice:\n",
    "                print(\"SAVING MAX VAL DICE SCORE MODEL\")\n",
    "                max_val_dice = (total_valid_dice_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "                torch.save(model.state_dict(), save_string + \"_max_val_dice_score.pt\")\n",
    "            if (total_valid_thresh_dice_score/math.ceil(valid_img_pro/valid_batch_size)) >= max_val_tice:\n",
    "                print(\"SAVING MAX VAL TICE SCORE MODEL\")\n",
    "                max_val_tice = (total_valid_thresh_dice_score/math.ceil(valid_img_pro/valid_batch_size))\n",
    "                torch.save(model.state_dict(), save_string + \"_max_val_tice_score.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfrKFjUird_D"
   },
   "source": [
    "# Save Training/Validation Data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUcSjrSRkDkX"
   },
   "outputs": [],
   "source": [
    "df_train_val_results = pd.DataFrame(data={'Train_Losses': train_ce_losses_lst, 'Valid_Losses': valid_ce_losses_lst,\n",
    "                                          'Train_DICE_Losses': train_dice_losses_lst, 'Valid_DICE_Losses': valid_dice_losses_lst,\n",
    "                                          'Train_DICE_Threshold_Losses': train_thresh_dice_losses_lst, 'Valid_DICE_Threshold_Losses': valid_thresh_dice_losses_lst,\n",
    "                                          'Train_DICE_Scores': train_dice_scores_lst, 'Valid_DICE_Scores': valid_dice_scores_lst,\n",
    "                                          'Train_DICE_Threshold_Scores': train_thresh_dice_scores_lst, 'Valid_DICE_Threshold_Scores': valid_thresh_dice_scores_lst,\n",
    "                                          'Train_IOU_Losses': train_iou_losses_lst, 'Valid_IOU_Losses': valid_iou_losses_lst,\n",
    "                                          'Train_IOU_Threshold_Losses': train_thresh_iou_losses_lst, 'Valid_IOU_Threshold_Losses': valid_thresh_iou_losses_lst,\n",
    "                                          'Train_IOU_Scores': train_iou_scores_lst, 'Valid_IOU_Scores': valid_iou_scores_lst,\n",
    "                                          'Train_IOU_Threshold_Scores': train_thresh_iou_scores_lst, 'Valid_IOU_Threshold_Scores': valid_thresh_iou_scores_lst,\n",
    "                                          'Train_PREC_Scores': train_precision_score_lst, 'Valid_PREC_Scores': valid_precision_score_lst,\n",
    "                                          'Train_RECALL_Scores': train_recall_score_lst ,'Valid_RECALL_Scores': valid_recall_score_lst })\n",
    "\n",
    "df_train_val_results.to_csv(save_string+\"_TRAIN-VAL.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model instance with highest validation thresholded dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = save_string + \"_max_val_tice_score.pt\"\n",
    "weights = torch.load(model_path)\n",
    "model.load_state_dict(weights, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_pro = 0\n",
    "total_test_ce_loss = 0\n",
    "total_test_dice_loss = 0\n",
    "total_test_dice_score = 0\n",
    "total_test_thresh_dice_loss = 0\n",
    "total_test_thresh_dice_score = 0\n",
    "total_test_iou_loss = 0\n",
    "total_test_iou_score = 0\n",
    "total_test_thresh_iou_loss = 0\n",
    "total_test_thresh_iou_score = 0\n",
    "total_test_precision_score = 0\n",
    "total_test_recall_score = 0\n",
    "max_test_batch = 1000000\n",
    "test_size = len(test_dataset)\n",
    "test_ce_losses_lst = []\n",
    "test_dice_losses_lst = []\n",
    "test_dice_scores_lst = []\n",
    "test_thresh_dice_losses_lst = []\n",
    "test_thresh_dice_scores_lst = []\n",
    "test_iou_losses_lst = []\n",
    "test_iou_scores_lst = []\n",
    "test_thresh_iou_losses_lst = []\n",
    "test_thresh_iou_scores_lst = []\n",
    "test_precision_score_lst = []\n",
    "test_recall_score_lst = []\n",
    "min_test_loss = 100\n",
    "max_test_dice = 0\n",
    "max_test_tice = 0\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Image Name', 'Dice Loss', 'Thresh Dice Loss',\n",
    "    'Thresh Dice Score', 'IoU Loss', 'Thresh IoU Loss',\n",
    "    'Thresh IoU Score', 'Precision Score', 'Recall Score'\n",
    "])\n",
    "\n",
    "# Ensure no_grad and evaluation mode are set to turn off batch norm and dropout\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for b, (name, img_test, msk_test) in enumerate(test_loader):\n",
    "        img_test, msk_test = img_test.to(device), msk_test.float().to(device)\n",
    "        # Apply the model\n",
    "        pred = model(img_test)\n",
    "        # Track Number of Images Processed\n",
    "        test_img_pro += pred.size()[0]\n",
    "\n",
    "        # Apply sigmoid activation (needed for dice and IoU loss calculations)\n",
    "        output = torch.sigmoid(pred)\n",
    "        binary_preds = (output > 0.5).int()\n",
    "        \n",
    "        # Save prediction maps for each image within the test set\n",
    "        for idx, img_name in enumerate(name):\n",
    "            img_path = f\"PATH TO MASK PREDICTION FOLDER/{img_name}\"\n",
    "            pred_data = binary_preds[idx].cpu().numpy().squeeze()\n",
    "            pred_data = (pred_data * 255).astype('uint8')\n",
    "            binary_img = Image.fromarray(pred_data)\n",
    "            binary_img.save(img_path)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, msk_test)\n",
    "        test_dice_loss = dice(output, msk_test)\n",
    "        test_dice_score = 1 - test_dice_loss\n",
    "        test_iou_loss = IoU(output, msk_test)\n",
    "        test_iou_score = 1 - test_iou_loss\n",
    "\n",
    "        # Calculate thresholded values\n",
    "        test_thresh_dice_loss = SIA_METRICS.Threshold_DiceLoss(output, msk_test, thresh=0.5, smooth=1e-6)\n",
    "        test_thresh_dice_score = 1 - test_thresh_dice_loss\n",
    "        test_thresh_iou_loss = SIA_METRICS.Threshold_IoULoss(output, msk_test, thresh=0.5, smooth=1e-6)\n",
    "        test_thresh_iou_score = 1 - test_thresh_iou_loss\n",
    "        test_precision_score = SIA_METRICS.custom_precision_score(output, msk_test, thresh=0.5, smooth=1e-6)\n",
    "        test_recall_score = SIA_METRICS.custom_recall_score(output, msk_test, thresh=0.5, smooth=1e-6)\n",
    "\n",
    "        for img_name in name:\n",
    "            temp_df = pd.DataFrame({\n",
    "                'Image Name': [img_name],\n",
    "                'Dice Loss': [test_dice_loss.item()],\n",
    "                'Thresh Dice Loss': [test_thresh_dice_loss.item()],\n",
    "                'Thresh Dice Score': [test_thresh_dice_score.item()],\n",
    "                'IoU Loss': [test_iou_loss.item()],\n",
    "                'Thresh IoU Loss': [test_thresh_iou_loss.item()],\n",
    "                'Thresh IoU Score': [test_thresh_iou_score.item()],\n",
    "                'Precision Score': [test_precision_score.item()],\n",
    "                'Recall Score': [test_recall_score.item()]\n",
    "            })\n",
    "            results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
    "\n",
    "        # Track the total multi-class losses to get epoch averages\n",
    "        total_test_ce_loss += loss.item()\n",
    "        total_test_dice_loss += test_dice_loss.item()\n",
    "        total_test_dice_score += test_dice_score.item()\n",
    "        total_test_iou_loss += test_iou_loss.item()\n",
    "        total_test_iou_score += test_iou_score.item()\n",
    "        total_test_thresh_dice_loss +=  test_thresh_dice_loss.item()\n",
    "        total_test_thresh_dice_score += test_thresh_dice_score.item()\n",
    "        total_test_thresh_iou_loss +=  test_thresh_iou_loss.item()\n",
    "        total_test_thresh_iou_score += test_thresh_iou_score.item()\n",
    "        total_test_precision_score += test_precision_score.item()\n",
    "        total_test_recall_score += test_recall_score.item()\n",
    "\n",
    "        # Print interim results\n",
    "        if b % (1 * batch_size) == 0:\n",
    "            print('*****************************************************************************************************************')\n",
    "            print(f' BATCH: {b:4} [{test_img_pro:6}/{test_size}] COMB LOSS: {total_test_ce_loss/math.ceil(test_img_pro/batch_size):7.5f} DICE LOSS: {total_test_dice_loss/math.ceil(test_img_pro/batch_size):7.5f} IOU LOSS: {total_test_iou_loss/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "            print(f'                                                      TICE LOSS: {total_test_thresh_dice_loss/math.ceil(test_img_pro/batch_size):7.5f} TOU LOSS: {total_test_thresh_iou_loss/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "            print(f'                                                      DICE SCRE: {total_test_dice_score/math.ceil(test_img_pro/batch_size):7.5f} IOU SCRE: {total_test_iou_score/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "            print(f'                                                      TICE SCRE: {total_test_thresh_dice_score/math.ceil(test_img_pro/batch_size):7.5f} TOU SCRE: {total_test_thresh_iou_score/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "            print(f'                                                      PREC SCRE: {total_test_precision_score/math.ceil(test_img_pro/batch_size):7.5f} REC SCRE: {total_test_recall_score/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "            print('*****************************************************************************************************************')\n",
    "\n",
    "    # Append average test loss of epoch to list\n",
    "    test_ce_losses_lst.append(total_test_ce_loss/math.ceil(test_img_pro/batch_size))\n",
    "    test_dice_losses_lst.append(total_test_dice_loss/math.ceil(test_img_pro/batch_size))\n",
    "    test_thresh_dice_losses_lst.append(total_test_thresh_dice_loss/math.ceil(test_img_pro/batch_size))\n",
    "    test_thresh_iou_losses_lst.append(total_test_thresh_iou_loss/math.ceil(test_img_pro/batch_size))\n",
    "    test_iou_losses_lst.append(total_test_iou_loss/math.ceil(test_img_pro/batch_size))\n",
    "    test_precision_score_lst.append(total_test_precision_score/math.ceil(test_img_pro/batch_size))\n",
    "    test_recall_score_lst.append(total_test_recall_score/math.ceil(test_img_pro/batch_size))\n",
    "    test_dice_scores_lst.append(total_test_dice_score/math.ceil(test_img_pro/batch_size))\n",
    "    test_thresh_dice_scores_lst.append(total_test_thresh_dice_score/math.ceil(test_img_pro/batch_size))\n",
    "    test_iou_scores_lst.append(total_test_iou_score/math.ceil(test_img_pro/batch_size))\n",
    "    test_thresh_iou_scores_lst.append(total_test_thresh_iou_score/math.ceil(test_img_pro/batch_size))\n",
    "\n",
    "# Print Results on test set\n",
    "print('#################################################################################################################')\n",
    "print(f'               TEST COMB LOSS: {total_test_ce_loss/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "print(f'               DICE LOSS: {total_test_dice_loss/math.ceil(test_img_pro/batch_size):7.5f} IOU LOSS: {total_test_iou_loss/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "print(f'               TICE LOSS: {total_test_thresh_dice_loss/math.ceil(test_img_pro/batch_size):7.5f} TOU LOSS: {total_test_thresh_iou_loss/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "print(f'               DICE SCRE: {total_test_dice_score/math.ceil(test_img_pro/batch_size):7.5f} IOU SCRE: {total_test_iou_score/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "print(f'               TICE SCRE: {total_test_thresh_dice_score/math.ceil(test_img_pro/batch_size):7.5f} TOU SCRE: {total_test_thresh_iou_score/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "print(f'               PREC SCRE: {total_test_precision_score/math.ceil(test_img_pro/batch_size):7.5f} REC SCRE: {total_test_recall_score/math.ceil(test_img_pro/batch_size):7.5f}')\n",
    "print('#################################################################################################################')\n",
    "\n",
    "# Save individual image predictions\n",
    "results_df.to_csv(save_string + '_TEST_RESULTS.csv', index=False)\n",
    "\n",
    "# Save single image averaged scores for the test set\n",
    "average_scores = {'Dice Loss': total_test_dice_loss / test_size,\n",
    "                  'Thresh Dice Loss': total_test_thresh_dice_loss / test_size,\n",
    "                  'Thresh Dice Score': total_test_thresh_dice_score / test_size,\n",
    "                  'IoU Loss': total_test_iou_loss / test_size,\n",
    "                  'Thresh IoU Loss': total_test_thresh_iou_loss / test_size,\n",
    "                  'Thresh IoU Score': total_test_thresh_iou_score / test_size,\n",
    "                  'Precision Score': total_test_precision_score / test_size,\n",
    "                  'Recall Score': total_test_recall_score / test_size}\n",
    "avg_df = pd.DataFrame([average_scores])\n",
    "avg_df.to_csv(save_string+'_AVERAGE_TEST_RESULTS.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMEjFfQiny+WCUVu1K6Nnal",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1ANfQ4pJWBkDbJcHshozvla0QzUkpCeYE",
   "provenance": [
    {
     "file_id": "1iy1ZNJU6m0znGIrkHFagOZ5FximSeMPk",
     "timestamp": 1692883746444
    },
    {
     "file_id": "1oaqdAb8OWOqYIfTJJd5ShtiKXLstTENA",
     "timestamp": 1691593883392
    },
    {
     "file_id": "1t2qesXNPtmnK_GT7xTpnFUL3Nt3yC7X4",
     "timestamp": 1691160592020
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
